## 什么是哈夫曼树

给定N个权值作为N个叶子结点，构造一棵二叉树，若该树的[带权路径长度](https://zhida.zhihu.com/search?content_id=180456551&content_type=Article&match_order=1&q=%E5%B8%A6%E6%9D%83%E8%B7%AF%E5%BE%84%E9%95%BF%E5%BA%A6&zhida_source=entity)达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树(Huffman Tree)。哈夫曼树是带权路径长度最短的树，权值较大的结点离根较近。

## 基本术语

哈夫曼树又称最优树

### 1️⃣ 路径和路径长度

在一棵树中，从一个结点往下可以达到的孩子或孙子结点之间的通路，称为路径。

通路中分支的数目称为路径长度。若规定根结点的层数为1，则从根结点到第L层结点的路径长度为L-1。

  

![[dcbe9cc4a373801b6d25eeaf8b696997_MD5.jpg]]

  

### 2️⃣ 节点的权和带权路径长度

若将树中结点赋给一个有着某种含义的数值，则这个数值称为该结点的权。
**结点的带权路径长度**为：**从根结点到该结点之间的路径长度与该结点的权的乘积**。

  

![[eb9a977e9e5ddbe98cecc6b050e4111c_MD5.jpg]]

  

### 3️⃣ 树的带权路径长度

树的带权路径长度规定为**所有叶子结点的带权路径长度之和**，记为WPL。

如上[[图论]]：数的带权路径长度为：

WPL = (2+3) * 3 + 4 * 2 + 6 * 1 = 29

## 哈夫曼树的构造

假设有n个权值，则构造出的哈夫曼树有n个叶子结点。 n个权值分别设为 w1、w2、…、wn，则哈夫曼树的构造规则为：

(1) 将w1、w2、…，wn看成是有n 棵树的森林(每棵树仅有一个结点)；
(2) 在森林中选出两个根结点的权值最小的树合并，作为一棵新树的左、右子树，且**新树的根结点权值为其左、右子树根结点权值之和**；
(3)从森林中删除选取的两棵树，并将新树加入森林；
(4)重复(2)、(3)步，直到森林中只剩一棵树为止，该树即为所求得的哈夫曼树。

例如：对 2，3，4，6 这四个数进行构造

  

![[705e62feb7f997eb8f6c39d15f3f2ac0_MD5.jpg]]

  

## 哈夫曼树的应用：[哈夫曼编码](https://zhida.zhihu.com/search?content_id=180456551&content_type=Article&match_order=1&q=%E5%93%88%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81&zhida_source=entity)

### 引言

> 哈夫曼编码的介绍

哈夫曼编码是一种压缩编码的编码算法，是基于哈夫曼树的一种编码方式。哈夫曼树又称为带权路径长度最短的二叉树。

哈夫曼编码跟 [ASCII 编码](https://zhida.zhihu.com/search?content_id=180456551&content_type=Article&match_order=1&q=ASCII+%E7%BC%96%E7%A0%81&zhida_source=entity)有什么区别？ASCII 编码是对照ASCII 表进行的编码，每一个字符符号都有对应的编码，其编码长度是固定的。而哈夫曼编码对于不同字符的出现频率其使用的编码是不一样的。其会对频率较高的字符使用较短的编码，频率低的字符使用较高的编码。这样保证总体使用的编码长度会更少，从而实现到了数据压缩的目的。

举一个例子：对字符串“aaa bb cccc dd e”使用 ASCII 进行编码得到的结果为：97 97 97 32 98 98 32 99 99 99 99 32 100 100 32 101 （十进制）需要 16 个字节，如果使用二进制表示的话需要 128位的内存空间去存储。

而如果使用 [Unicode](https://zhida.zhihu.com/search?content_id=180456551&content_type=Article&match_order=1&q=Unicode&zhida_source=entity) 的话会更多，因为 Unicode 又称为万国码，内容更多，因此使用的空间也需要更大。

接下来使用哈夫曼编码对上面的字符串进行编码。看看需要多大的空间

### 统计频率

上面的介绍已经说明了哈夫曼编码会根据字符出现的频率从而条件字符使用的编码长度。因此要先求出这个字符串中每个字符出现的频率

|字符|c|' ' 空|a|b|d|e|
|---|---|---|---|---|---|---|
|频率|4|4|3|2|2|1|

### 构建哈夫曼树
[[哈夫曼树.cpp]]
> 排序

哈夫曼树是一个带权的二叉树，而在哈夫曼编码中，字符的出现频率就是字符的权重。因此要根据字符的频率放入[[优先队列]]中进行排序。然后根据这些字符构建一棵哈夫曼树

|字符|e|d|b|a|' ' 空|c|
|---|---|---|---|---|---|---|
|频率|1|2|2|3|4|4|

将队列中的每一个元素（字符）都看成一棵树。

> 合并

进行迭代，每次都去除队列中的前面两个元素，也就是权值最小的两棵子树进行合并成一棵子树。直到最终所有的元素合并成一棵树。这棵树就是哈夫曼树。

合并步骤
>[!tip] 注意哈夫曼树首先是在一个递增的数列进行操作

合并 1、2 权值为 3：

  

![[e03c50e77a39f56b2ae80e40d2a611e5_MD5.jpg]]

  

将 3这棵树重新插入队列：

  

![[fa6460303d6837ee3a8356fcf83e6c7a_MD5.jpg]]

  

合并 2、3 生成 5 的树，并插入队列：

  

![[2ab54a51a5aec3df9de1a24fca8c901c_MD5.jpg]]

  

合并 3、4 生成 7 的树，并插入队列：

  

![[769220d3ba61e4f526dda9404c3fea43_MD5.jpg]]

  

合并 4、5 生成 9 的数，并插入队列：

  

![[cfce6d358e65ab13932cf8d20d8d0fc4_MD5.jpg]]

  

合并 7、9 生成 16 的树，最终只有一棵树，该树便是这个字符串所生成的哈夫曼树：

  

![[bcfd6d279bf44f5435f536586cf6958a_MD5.jpg]]

  

### 为哈夫曼树进行编码

重点：**将二叉树分支中的左分支编为 0，右分支编为 1：**

  0和1分别对应两种状态，共有$2^n$种状态，可以用于表示每个节点
  

![[b7d4e9191b118591f6fd529348dcb71f_MD5.jpg]]

  

可以发现每个字符都在树的叶子节点上，因此要获取每个字符的哈夫曼编码，就通过根节点遍历到对应的子节点所经历的路径就是这个字符的编码：

| 字符  | e    | d    | b   | a   | ' ' | c   |
| --- | ---- | ---- | --- | --- | --- | --- |
| 编码  | 1110 | 1111 | 110 | 00  | 01  | 10  |
原理：让频率高的放到哈夫曼树的顶端，编码长度比较短，让频率低的放到底端，编码长度长
可以发现使用频率高的字符`e` 其编码长度是比出现频率低的字符`c` 编码长度要少。最后计算使用哈夫曼编码的字符串“aaa bb cccc dd e”要使用多少位的内存空间进行存储：出现次数 * 编码长度。结果为 4 * 3 + 3 * 2 + 11 * 2 = 40位，与 ASCII 对应的 128位，少了2/3的存储空间。

### 码长
### **码长的定义与计算**

码长在哈夫曼编码中表示**每个字符对应的二进制编码的位数**，其计算与字符的出现频率（或概率）直接相关。以下是具体解析：

---

#### ​**1. 码长的定义**

- ​**单个字符的码长**：在哈夫曼树中，每个字符的编码长度等于**该字符在树中的深度**​（即从根节点到该字符节点的路径边数）
- ​**平均码长**：所有字符的码长按出现频率加权后的平均值，即：平均码长=∑(字符频率×码长)例如，若字符`A`出现频率为0.2，码长为3位，则其贡献值为 0.2×3
---

#### ​**2. 码长的计算步骤**

以哈夫曼编码为例：

1. ​**构建哈夫曼树**：
    - 将字符按频率升序排列，每次合并频率最小的两个节点，生成新节点（权重为两者之和），直至只剩一个根节点
    - 合并过程中，左分支标记为`0`，右分支标记为`1`
2. ​**确定字符码长**：
    - 从根节点到叶子节点的路径长度即为该字符的码长。例如，频率高的字符（如41的`L`）路径短，码长为1；频率低的字符（如2的`A`）路径长，码长为11

**示例**：  
对字符集 `(A:2, B:3, C:5, D:7, E:11, F:13, G:17, H:19, I:23, J:31, K:37, L:41)`，哈夫曼编码后：

- `L`（频率41）的码长为1（路径`0`）；
- `A`（频率2）的码长为11（路径`11111111111`）

---

#### ​**3. 平均码长与信息熵的关系**

- ​**信息熵**：表示信源的最小理论平均码长，公式为：H=−∑(pi​log2​pi​)例如，若字符概率分布为 `(0.2, 0.19, 0.18, 0.17, 0.15, 0.10, 0.01)`，熵为2.61 bit，而哈夫曼编码的平均码长为2.72 bit
- ​**压缩效率**：哈夫曼编码的平均码长接近信息熵，但略大于熵
---
#### ​**4. 码长的应用与特性**

- ​**前缀码性质**：任一字符的编码都不是其他字符编码的前缀，确保解码唯一性
- ​**最优性**：在所有变长编码中，哈夫曼编码的平均码长最短
- ​**局限性**：当字符概率分布均匀时，压缩效果有限；需精确统计字符频率

# 例题实战

## 给出节点，求出最小带权路径

### 代码
```cpp
// 二叉树的带权路径长度 这实际上是一个哈夫曼树的构建问题
#include <iostream>
#include <vector>
#include <algorithm>
using namespace std;

int main()
{
    while (1)
    {
        int n; // 叶子节点个数
        cin >> n;
        if (n == 0)
            break;
        vector<int> a(n);
        for (int i = 0; i < n; i++)
        {
            cin >> a[i];
        }

        sort(a.begin(), a.end()); // 从小到大排序

        int wpl = 0; // 最小带权路径长度
        while (a.size() > 1)
        {
            // 1. 取出最小的两个权值
            int first = a[0];
            int second = a[1];

            // 2. 计算合并后的权值
            int merged = first + second;
            wpl += merged; // 累加到 WPL

            // 3. 删除最小的两个权值
            a.erase(a.begin(), a.begin() + 2);

            // 4. 将合并后的权值插入到合适的位置，并保持有序
            auto it = lower_bound(a.begin(), a.end(), merged);
            a.insert(it, merged);
        }

        cout << wpl << endl; // 输出最小带权路径长度
    }
    return 0;
}
```
WPL
```cpp


```

## 为什么wsl就是最小带权路径
>你提出了一个非常关键的问题！ 你的理解是正确的，WPL 的确是权值乘以路径长度的总和。 让我来详细解释一下为什么之前的代码（以及哈夫曼树的构建过程）能够正确计算 WPL。

### 关键理解

1.  **哈夫曼树的构建过程**

    *   每次选择权值最小的两个节点合并，创建一个新的父节点。
    *   新父节点的权值为两个子节点的权值之和。
    *   这个新父节点会继续参与后续的合并过程，直到最终形成根节点。

2.  **WPL 的计算**

    *   在每次合并两个节点时，将它们的权值之和累加到 WPL 中。
    *   这个累加的过程，实际上就是在计算每个叶子节点的权值乘以其路径长度的总和。

### 为什么累加权值之和等于 WPL

假设有三个叶子节点，权值分别为 w1、w2、w3。

1.  **第一次合并**

    *   选择 w1 和 w2 合并，创建一个新节点，权值为 w1 + w2。
    *   WPL 增加 w1 + w2。
    *   此时，w1 和 w2 的路径长度都增加了 1。

2.  **第二次合并**

    *   选择 w1 + w2 和 w3 合并，创建一个新节点，权值为 w1 + w2 + w3。
    *   WPL 增加 w1 + w2 + w3。
    *   此时，w1、w2 和 w3 的路径长度又都增加了 1。

3.  **最终 WPL**

    *   WPL = (w1 + w2) + (w1 + w2 + w3) = 2w1 + 2w2 + w3。
    *   这相当于 w1 和 w2 的路径长度为 2，w3 的路径长度为 1。

### 推广到一般情况

*   每次合并两个节点时，相当于将这两个节点的所有子节点的路径长度都增加了 1。
*   因此，每次累加权值之和，实际上就是在计算每个叶子节点的权值乘以其路径长度的总和。

### 你的问题

*   **“这个不断累加的过程，是不是刚好进行了 n（节点所在的层数）次？”**

    *   不是刚好进行了 n 次，而是每次合并都会将一部分节点的路径长度增加 1，并将其权值之和累加到 WPL 中。
    *   最终，每个叶子节点的权值都会被累加到 WPL 中，累加的次数等于其路径长度。

### 总结

哈夫曼树的构建过程巧妙地利用了贪心策略，通过每次合并权值最小的两个节点，使得 WPL 达到最小。 每次累加权值之和，实际上就是在计算每个叶子节点的权值乘以其路径长度的总和，从而得到最小带权路径长度。